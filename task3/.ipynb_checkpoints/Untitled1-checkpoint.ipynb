{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8aea49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import truncnorm\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.special import expit as activation_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0e931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "df2 = pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0706f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)\n",
    "np.random.shuffle(data)\n",
    "n_samples,n_features = data.shape\n",
    "\n",
    "data_train = data[0:n_samples].T\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:n_features]/255\n",
    "#data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "082b498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data[0:n_samples].T\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:n_features]/255\n",
    "#X_test\n",
    "#data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aeaa021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of these helper functions were taken from the labs 6 and 7\n",
    "\n",
    "#relu function\n",
    "@np.vectorize\n",
    "def ReLU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "#dderivative of Relu\n",
    "@np.vectorize\n",
    "def d_ReLU(x):\n",
    "    return x > 0\n",
    "\n",
    "#softmax function\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "#sigmoid function\n",
    "@np.vectorize\n",
    "#def sigmoid(x):\n",
    " #   return 1 / (1 + np.e ** -x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    if x < 0:\n",
    "        return np.exp(x)/(1+np.exp(x))\n",
    "    else:\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "#derivative of sigmoid\n",
    "@np.vectorize\n",
    "def d_sigmoid(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "\n",
    "def one_hot_encode_Y(Y):\n",
    "    newY = np.zeros ( (Y.size, Y.max() + 1))\n",
    "    newY[np.arange(Y.size), Y] = 1\n",
    "    newY = newY.T\n",
    "    return newY\n",
    "\n",
    "#this function I created myself for the stopping critera\n",
    "def difference(arr):\n",
    "    return [item-arr[i-1] for i, item in enumerate(arr) if i != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c2b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork():\n",
    "    \n",
    "    def __init__(self, \n",
    "                 no_of_in_nodes, \n",
    "                 no_of_out_nodes, \n",
    "                 no_of_hidden_nodes,\n",
    "                 learning_rate):\n",
    "        self.no_of_in_nodes = no_of_in_nodes\n",
    "        self.no_of_out_nodes = no_of_out_nodes\n",
    "        self.no_of_hidden_nodes = no_of_hidden_nodes\n",
    "        self.learning_rate = learning_rate \n",
    "        self.create_weight_matrices()\n",
    "        self.newY = one_hot_encode_Y(self.no_of_out_nodes)\n",
    "        \n",
    "    def create_weight_matrices(self):\n",
    "        self.w1 = np.random.rand(self.no_of_hidden_nodes, 784) - 0.5 \n",
    "        self.b1 = np.random.rand(self.no_of_hidden_nodes, 1) - 0.5\n",
    "        self.w2 = np.random.rand(self.no_of_hidden_nodes, self.no_of_hidden_nodes) - 0.5 \n",
    "        self.b2 = np.random.rand(self.no_of_hidden_nodes, 1) - 0.5\n",
    "        self.w3 = np.random.rand(self.no_of_hidden_nodes, self.no_of_hidden_nodes) - 0.5 \n",
    "        self.b3 = np.random.rand(self.no_of_hidden_nodes, 1) - 0.5\n",
    "        \n",
    "        return self.w1, self.b1, self.w2, self.b2, self.w3, self.b3\n",
    "    \n",
    "    def get_predictions(self):\n",
    "        return np.argmax(self.a2, 0)\n",
    "\n",
    "    def get_accuracy(self,predictions):\n",
    "        return (np.sum(predictions == self.no_of_out_nodes) / self.no_of_out_nodes.size) * 100\n",
    "        \n",
    "    def SGDTrain(self, epochs):\n",
    "        self.create_weight_matrices()\n",
    "        acc_list = []\n",
    "        for i in range(epochs):\n",
    "            \n",
    "            #forward pass with both\n",
    "            self.z1 = self.w1.dot(self.no_of_in_nodes) + self.b1\n",
    "            self.a1 = ReLU(self.z1)\n",
    "            self.z2 = self.w2.dot(self.a1) + self.b2\n",
    "            self.a2 = sigmoid(self.z2)\n",
    "            self.z3 = self.w3.dot(self.a2) + self.b3\n",
    "            self.a3 = softmax(self.z3)\n",
    "            \n",
    "            #backwards pass with both\n",
    "            scaling = 1/self.no_of_out_nodes.size    \n",
    "            self.z3_delta = self.a3 - self.newY\n",
    "            self.w3_delta = scaling * self.z3_delta.dot(self.a2.T)\n",
    "            self.b3_delta = scaling * np.sum(self.z3_delta)\n",
    "            self.z2_delta = self.w3.T.dot(self.z3_delta) * d_ReLU(self.z2)\n",
    "            self.w2_delta = scaling * self.z2_delta.dot(self.a1.T)\n",
    "            self.b2_delta = scaling * np.sum(self.z2_delta)\n",
    "            self.z1_delta = self.w2.T.dot(self.z2_delta) * d_sigmoid(self.z1)\n",
    "            self.w1_delta = scaling * self.z1_delta.dot(self.no_of_in_nodes.T)\n",
    "            self.b1_delta = scaling * np.sum(self.z1_delta)\n",
    "            \n",
    "            \n",
    "            #update weights\n",
    "            self.w1 -= self.learning_rate * self.w1_delta\n",
    "            self.b1 -= self.learning_rate * self.b1_delta\n",
    "            self.w2 -= self.learning_rate * self.w2_delta\n",
    "            self.b2 -= self.learning_rate * self.b2_delta\n",
    "            self.w3 -= self.learning_rate * self.w3_delta\n",
    "            self.b3 -= self.learning_rate * self.b3_delta\n",
    "            \n",
    "            \n",
    "            print(f'epoch: {i+1}') \n",
    "            print(f'Accuracy: {(self.get_accuracy(self.get_predictions ())):.2f}%')\n",
    "            acc_list.append(self.get_accuracy(self.get_predictions ()))\n",
    "            \n",
    "            #stopping criteria so if accuracy increase 2 times in a row is less than 0.2 it stops training\n",
    "            diff = difference(acc_list[-3:])\n",
    "            if len(diff) > 1:\n",
    "                if(diff[-1] < 0.2 and diff[-2] < 0.2):\n",
    "                    break\n",
    "                #debugging my stopping criteria\n",
    "              #  print(diff[-1])\n",
    "        return acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f667d0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Accuracy: 12.08%\n",
      "epoch: 2\n",
      "Accuracy: 8.58%\n",
      "epoch: 3\n",
      "Accuracy: 10.01%\n",
      "epoch: 4\n",
      "Accuracy: 10.00%\n",
      "epoch: 5\n",
      "Accuracy: 10.00%\n"
     ]
    }
   ],
   "source": [
    "model = neuralNetwork(X_train,Y_train, 10 ,0.1)\n",
    "acc = model.SGDTrain(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4229d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5f2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
